{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from mnist import MNIST\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset....\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading dataset....\")\n",
    "mndata = MNIST('../mnist_dataset')\n",
    "X_train, y_train = mndata.load_training()\n",
    "X_train = (mndata.process_images_to_numpy(X_train)/255)\n",
    "X_test, y_test = mndata.load_testing()\n",
    "X_test = (mndata.process_images_to_numpy(X_test)/255)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(labels):\n",
    "    y_inp=np.zeros((len(labels),10))\n",
    "    for ind,val in enumerate(labels):\n",
    "        y_inp[ind][val]=1\n",
    "    return y_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_gen(st=0,size=20,validate=False):\n",
    "    st=st%60000\n",
    "    if validate:\n",
    "        X=X_test[st:st+size].reshape(-1,28*28*1)\n",
    "        labels=y_test[st:st+size]\n",
    "    else:\n",
    "        X=X_train[st:st+size].reshape(-1,28*28*1)\n",
    "        labels=y_train[st:st+size]\n",
    "    y=one_hot_encode(labels)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 428\n",
      "Seed: 396\n"
     ]
    }
   ],
   "source": [
    "from nnet.network import Sequential,layers\n",
    "from nnet.layers import conv2d,max_pool,flatten,dense,dropout,Activation\n",
    "from nnet import functions\n",
    "from nnet import optimizers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(dense(128,input_shape=(784),activation=functions.sigmoid))\n",
    "model.add(dense(32,activation=functions.sigmoid))\n",
    "model.add(dense(10))\n",
    "model.add(Activation(functions.sigmoid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽\n",
      "Layer (type)               Output Shape             Activation        Param #\n",
      "==========================================================================================\n",
      "0 input_layer(InputLayer) (None, 784)                echo             0\n",
      "__________________________________________________________________________________________\n",
      "1 dense(dense)            (None, 128)                sigmoid          100480\n",
      "__________________________________________________________________________________________\n",
      "2 dense(dense)            (None, 32)                 sigmoid          4128\n",
      "__________________________________________________________________________________________\n",
      "3 dense(dense)            (None, 10)                 echo             330\n",
      "__________________________________________________________________________________________\n",
      "4 Activation(Activation)  (None, 10)                 sigmoid          0\n",
      "==========================================================================================\n",
      "Total Params: 104,938\n",
      "Trainable Params: 104,938\n",
      "Non-trainable Params: 0\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizers.adam,loss=functions.mean_squared_error,learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate():\n",
    "    vdsz=2000\n",
    "    dvme=10000//vdsz\n",
    "    acc=0\n",
    "    cross_entropy_loss=0\n",
    "    for smpl in range(0,10000,vdsz):\n",
    "        print(\"\\rCalculating Validation acc...\",smpl//vdsz+1,end='')\n",
    "        inp,y_inp=batch_gen(smpl,size=vdsz,validate=True)\n",
    "        logits=model.predict(inp)\n",
    "        ans=logits.argmax(axis=1)\n",
    "        cor=y_inp.argmax(axis=1)\n",
    "        acc+=100*(ans==cor).mean()\n",
    "        cross_entropy_loss+=model.loss(logits,labels=y_inp).mean()*10\n",
    "    print(\"\\rValidation Acc: {:.3f} %        Val loss: {:.8f}\".format(acc/dvme,cross_entropy_loss/dvme))\n",
    "    logits=model.predict(inp[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    st=0\n",
    "    btsz=128\n",
    "    acc_tn=0\n",
    "    _cc=0\n",
    "    loss_tn=0\n",
    "    while st<=60000:\n",
    "        sam_tm=time()\n",
    "        perc=st/600\n",
    "        ck=np.random.randint(0,60000-btsz)\n",
    "        inp,y_inp=batch_gen(ck,size=btsz)\n",
    "        logits=model.fit(inp,y_inp)\n",
    "        ans=logits.argmax(axis=1)\n",
    "        cor=y_inp.argmax(axis=1)\n",
    "        acc=100*(ans==cor).mean()\n",
    "        cross_entropy_loss=model.loss(logits=logits,labels=y_inp).mean()*10\n",
    "        acc_tn+=acc\n",
    "        _cc+=1\n",
    "        loss_tn+=cross_entropy_loss\n",
    "        acc=acc_tn/_cc\n",
    "        loss_=loss_tn/_cc\n",
    "        if acc>=98:\n",
    "            model.learning_rate=1e-5\n",
    "        elif acc>=97:\n",
    "            model.learning_rate=1e-4\n",
    "#         elif acc>=95:\n",
    "#             model.learning_rate=1e-4\n",
    "        sam_tm=time()-sam_tm\n",
    "        rem_sam=(60000-st)/btsz\n",
    "        eta=int(rem_sam*sam_tm)\n",
    "        print(\"\\rProgress: {:.2f} %    Acc: {:.3f} %    loss: {:.6f}     Sample time: {:.3f}s    ETA: {}:{}s    .\".format(perc,acc,loss_,sam_tm,eta//60,eta%60),end='')\n",
    "        st+=btsz\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1 / 3\n",
      "Progress: 99.84 %    Acc: 11.301 %    loss: 0.470415     Sample time: 0.015s    ETA: 0:0s    ..\n",
      "Epoch time: 0:3s\n",
      "Validation Acc: 11.350 %        Val loss: 0.44989031\n",
      "EPOCH: 2 / 3\n",
      "Progress: 99.84 %    Acc: 11.326 %    loss: 0.449862     Sample time: 0.018s    ETA: 0:0s    .\n",
      "Epoch time: 0:3s\n",
      "Validation Acc: 11.350 %        Val loss: 0.44987267\n",
      "EPOCH: 3 / 3\n",
      "Progress: 99.84 %    Acc: 11.172 %    loss: 0.449877     Sample time: 0.014s    ETA: 0:0s    .\n",
      "Epoch time: 0:3s\n",
      "Validation Acc: 11.350 %        Val loss: 0.44988079\n"
     ]
    }
   ],
   "source": [
    "epochs=3\n",
    "for epoch in range(epochs):\n",
    "    print(\"EPOCH:\",epoch+1,'/',epochs)\n",
    "    st_tm=time()\n",
    "    run()\n",
    "    print(\"Epoch time: {}:{}s\".format(int(time()-st_tm)//60,int(time()-st_tm)%60))\n",
    "    validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
