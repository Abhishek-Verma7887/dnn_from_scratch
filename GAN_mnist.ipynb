{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from mnist import MNIST\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset....\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading dataset....\")\n",
    "mndata = MNIST('../mnist_dataset')\n",
    "X_train, y_train = mndata.load_training()\n",
    "X_train = (mndata.process_images_to_numpy(X_train)/255)\n",
    "X_test, y_test = mndata.load_testing()\n",
    "X_test = (mndata.process_images_to_numpy(X_test)/255)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(labels):\n",
    "    y_inp=np.zeros((len(labels),10))\n",
    "    for ind,val in enumerate(labels):\n",
    "        y_inp[ind][val]=1\n",
    "    return y_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_gen(st=0,size=20,validate=False):\n",
    "    st=st%60000\n",
    "    if validate:\n",
    "        X=X_test[st:st+size].reshape(-1,28,28,1)\n",
    "        labels=y_test[st:st+size]\n",
    "    else:\n",
    "        X=X_train[st:st+size].reshape(-1,28,28,1)\n",
    "        labels=y_train[st:st+size]\n",
    "    y=one_hot_encode(labels)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 211\n",
      "Seed: 262\n"
     ]
    }
   ],
   "source": [
    "from nnet.network import Sequential,layers\n",
    "from nnet.layers import conv2d,max_pool,flatten,dense,dropout\n",
    "from nnet import functions\n",
    "from nnet import optimizers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator():\n",
    "    model=Sequential()\n",
    "    model.add(dense(256,input_shape=(100),activation=functions.relu))\n",
    "    model.add(dense(512,activation=functions.relu))\n",
    "    model.add(dense(1024,activation=functions.relu))\n",
    "    model.add(dense(784,activation=functions.sigmoid))\n",
    "    return model\n",
    "g=generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽\n",
      "Layer (type)               Output Shape             Activation        Param #\n",
      "==========================================================================================\n",
      "0 input_layer(InputLayer) (None, 100)                echo             0\n",
      "__________________________________________________________________________________________\n",
      "1 dense(dense)            (None, 256)                relu             25856\n",
      "__________________________________________________________________________________________\n",
      "2 dense(dense)            (None, 512)                relu             131584\n",
      "__________________________________________________________________________________________\n",
      "3 dense(dense)            (None, 1024)               relu             525312\n",
      "__________________________________________________________________________________________\n",
      "4 dense(dense)            (None, 784)                sigmoid          803600\n",
      "==========================================================================================\n",
      "Total Params: 1,486,352\n",
      "Trainable Params: 1,486,352\n",
      "Non-trainable Params: 0\n"
     ]
    }
   ],
   "source": [
    "g.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator():\n",
    "    model=Sequential()\n",
    "    model.add(dense(1024,input_shape=(784),activation=functions.relu))\n",
    "    model.add(dropout(0.3))\n",
    "    model.add(dense(512,activation=functions.relu))\n",
    "    model.add(dropout(0.3))\n",
    "    model.add(dense(256,activation=functions.relu))\n",
    "    model.add(dense(1,activation=functions.sigmoid))\n",
    "    return model\n",
    "d=discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽\n",
      "Layer (type)               Output Shape             Activation        Param #\n",
      "==========================================================================================\n",
      "0 input_layer(InputLayer) (None, 784)                echo             0\n",
      "__________________________________________________________________________________________\n",
      "1 dense(dense)            (None, 1024)               relu             803840\n",
      "__________________________________________________________________________________________\n",
      "2 dropout(dropout)        (None, 1024)               echo             0\n",
      "__________________________________________________________________________________________\n",
      "3 dense(dense)            (None, 512)                relu             524800\n",
      "__________________________________________________________________________________________\n",
      "4 dropout(dropout)        (None, 512)                echo             0\n",
      "__________________________________________________________________________________________\n",
      "5 dense(dense)            (None, 256)                relu             131328\n",
      "__________________________________________________________________________________________\n",
      "6 dense(dense)            (None, 1)                  sigmoid          257\n",
      "==========================================================================================\n",
      "Total Params: 1,460,225\n",
      "Trainable Params: 1,460,225\n",
      "Non-trainable Params: 0\n"
     ]
    }
   ],
   "source": [
    "d.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.compile(optimizer=optimizers.adam,loss=functions.cross_entropy_with_logits,learning_rate=0.01)\n",
    "d.compile(optimizer=optimizers.adam,loss=functions.cross_entropy_with_logits,learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan(gan_input,labels):\n",
    "    x = g.fit(gan_input,labels)\n",
    "    gan_out = d.predict(x)\n",
    "    return gan_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    batch_size=64\n",
    "    dsz=X_train.shape[0]\n",
    "    for _b in range(dsz//batch_size):\n",
    "        stt=time()\n",
    "        noise=np.random.normal(0,1,(batch_size,100))\n",
    "        # Generate fake images from noise\n",
    "        generated_images=g.predict(noise)\n",
    "        # Get random real images\n",
    "        real_images=X_train[np.random.randint(low=0,high=dsz,size=batch_size)]\n",
    "        X = np.concatenate([real_images,generated_images])\n",
    "        # Label real ones as 90% real\n",
    "        y_dis=np.zeros((2*batch_size,1))\n",
    "        y_dis[:batch_size]=0.99\n",
    "        # Train discriminator\n",
    "        d.fit(X,y_dis)\n",
    "        print(\"\\rProgress: {:.2f} %     Sample time: {:.3f}s    _\".format(_b*batch_size*50/dsz,time()-stt),end='')\n",
    "    for _b in range(dsz//batch_size):\n",
    "        stt=time()\n",
    "        # Treat noised input of generator as real data\n",
    "        noise=np.random.normal(0,1,(batch_size,100))\n",
    "        y_gen=np.ones((batch_size,1))\n",
    "        # Train generator\n",
    "        g.fit(noise,y_gen)\n",
    "        print(\"\\rProgress: {:.2f} %     Sample time: {:.3f}s    _\".format(50+_b*batch_size*50/dsz,time()-stt),end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=50\n",
    "for epoch in range(epochs):\n",
    "    print(\"EPOCH:\",epoch+1,'/',epochs)\n",
    "    st_tm=time()\n",
    "    run()\n",
    "    print(\"Epoch time: {}:{}s\".format(int(time()-st_tm)//60,int(time()-st_tm)%60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise=np.random.normal(0,1,(1,100))\n",
    "plt.imshow(g.predict(noise).reshape(28,28), cmap='Greys')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.predict(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
