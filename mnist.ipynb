{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from mnist import MNIST\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset....\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading dataset....\")\n",
    "mndata = MNIST('../mnist_dataset')\n",
    "X_train, y_train = mndata.load_training()\n",
    "X_train = (mndata.process_images_to_numpy(X_train)/255)\n",
    "X_test, y_test = mndata.load_testing()\n",
    "X_test = (mndata.process_images_to_numpy(X_test)/255)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(labels):\n",
    "    y_inp=np.zeros((len(labels),10))\n",
    "    for ind,val in enumerate(labels):\n",
    "        y_inp[ind][val]=1\n",
    "    return y_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_gen(st=0,size=20,validate=False):\n",
    "    st=st%60000\n",
    "    if validate:\n",
    "        X=X_test[st:st+size].reshape(-1,28,28,1)\n",
    "        labels=y_test[st:st+size]\n",
    "    else:\n",
    "        X=X_train[st:st+size].reshape(-1,28,28,1)\n",
    "        labels=y_train[st:st+size]\n",
    "    y=one_hot_encode(labels)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import network, layers and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from network import Sequential,layers\n",
    "from layers import conv2d,max_pool,flatten,dense\n",
    "import functions\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(conv2d(input_shape=(28,28,1),num_kernels=16,kernel_size=5,activation=functions.relu))\n",
    "model.add(max_pool())\n",
    "model.add(conv2d(num_kernels=32,kernel_size=5,activation=functions.relu))\n",
    "model.add(max_pool())\n",
    "model.add(flatten())\n",
    "model.add(dense(256,activation=functions.relu))\n",
    "model.add(dense(64,activation=functions.relu))\n",
    "model.add(dense(10,activation=functions.softmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽\n",
      "Name (type)                     Output Shape             Activation        Param #\n",
      "==========================================================================================\n",
      "input_layer (InputLayer)       (None, 28, 28, 1)          echo             0\n",
      "__________________________________________________________________________________________\n",
      "conv2d (conv2d)                (None, 28, 28, 16)         relu             416\n",
      "__________________________________________________________________________________________\n",
      "max_pool (max_pool)            (None, 14, 14, 16)         echo             0\n",
      "__________________________________________________________________________________________\n",
      "conv2d (conv2d)                (None, 14, 14, 32)         relu             12832\n",
      "__________________________________________________________________________________________\n",
      "max_pool (max_pool)            (None, 7, 7, 32)           echo             0\n",
      "__________________________________________________________________________________________\n",
      "flatten (flatten)              (None, 1568)               echo             0\n",
      "__________________________________________________________________________________________\n",
      "dense (dense)                  (None, 256)                relu             401664\n",
      "__________________________________________________________________________________________\n",
      "dense (dense)                  (None, 64)                 relu             16448\n",
      "__________________________________________________________________________________________\n",
      "dense (dense)                  (None, 10)                 softmax          650\n",
      "==========================================================================================\n",
      "Total Params: 432010\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile model with optimizer, loss and lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=functions.adam,loss=functions.cross_entropy_with_logits,learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses=[]\n",
    "val_losses=[]\n",
    "train_acc=[]\n",
    "val_acc=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def run():\n",
    "    st=0\n",
    "    btsz=8\n",
    "    cuts=(((60000*np.arange(11)/10))//btsz)*btsz\n",
    "    while st<=60000:\n",
    "        perc=st/600\n",
    "        ck=np.random.randint(0,60000-btsz)\n",
    "        inp,y_inp=batch_gen(ck,size=btsz)\n",
    "        logits=model.fit(inp,y_inp)\n",
    "        ans=logits.argmax(axis=1)\n",
    "        cor=y_inp.argmax(axis=1)\n",
    "        acc=100*(ans==cor).mean()\n",
    "        cross_entropy_loss=model.loss(logits=logits,labels=y_inp).mean()\n",
    "        losses.append(cross_entropy_loss)\n",
    "        train_acc.append(acc)\n",
    "        print(\"\\rProgress: {:.2f} %\\tAcc: {:.2f} %\\tloss: {:.8f}\".format(perc,acc,cross_entropy_loss),end='')\n",
    "        if st in cuts:\n",
    "            print(\"\\nCalculating Validation acc...\",end='')\n",
    "            sz=4000\n",
    "#             ck=0\n",
    "            ck=np.random.randint(0,10000-sz)\n",
    "            inp,y_inp=batch_gen(ck,size=sz,validate=True)\n",
    "            logits=model.predict(inp)\n",
    "            ans=logits.argmax(axis=1)\n",
    "            cor=y_inp.argmax(axis=1)\n",
    "            acc=100*(ans==cor).mean()\n",
    "            cross_entropy_loss=model.loss(logits,labels=y_inp).mean()\n",
    "            print(\"\\rValidation Acc: {:.2f} %\\t\\tVal loss: {:.8f}\".format(acc,cross_entropy_loss))\n",
    "            val_losses.append(cross_entropy_loss)\n",
    "            val_acc.append(acc)\n",
    "            if acc>=96:\n",
    "                model.learning_rate=0.00001\n",
    "            elif acc>=93:\n",
    "                model.learning_rate=0.0001\n",
    "            elif acc>=90:\n",
    "                model.learning_rate=0.001\n",
    "        st+=btsz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 0.00 %\tAcc: 100.00 %\tloss: 0.00018377\n",
      "Validation Acc: 95.38 %\t\tVal loss: 0.01519213\n",
      "Progress: 10.00 %\tAcc: 100.00 %\tloss: 0.00011396\n",
      "Validation Acc: 97.20 %\t\tVal loss: 0.00869963\n",
      "Progress: 20.00 %\tAcc: 100.00 %\tloss: 0.01608957\n",
      "Validation Acc: 96.78 %\t\tVal loss: 0.01035080\n",
      "Progress: 30.00 %\tAcc: 100.00 %\tloss: 0.00009648\n",
      "Validation Acc: 96.45 %\t\tVal loss: 0.01130031\n",
      "Progress: 40.00 %\tAcc: 100.00 %\tloss: 0.00020198\n",
      "Validation Acc: 98.88 %\t\tVal loss: 0.00387886\n",
      "Progress: 50.00 %\tAcc: 100.00 %\tloss: 0.00430515\n",
      "Validation Acc: 96.58 %\t\tVal loss: 0.01080264\n",
      "Progress: 60.00 %\tAcc: 100.00 %\tloss: 0.00010976\n",
      "Validation Acc: 96.90 %\t\tVal loss: 0.00965760\n",
      "Progress: 70.00 %\tAcc: 100.00 %\tloss: 0.00137612\n",
      "Validation Acc: 97.80 %\t\tVal loss: 0.00720352\n",
      "Progress: 80.00 %\tAcc: 100.00 %\tloss: 0.00016424\n",
      "Validation Acc: 98.92 %\t\tVal loss: 0.00378992\n",
      "Progress: 90.00 %\tAcc: 87.50 %\tloss: 0.143654791\n",
      "Validation Acc: 99.05 %\t\tVal loss: 0.00332965\n",
      "Progress: 100.00 %\tAcc: 87.50 %\tloss: 0.01912425\n",
      "Validation Acc: 97.40 %\t\tVal loss: 0.00818042\n",
      "Progress: 0.00 %\tAcc: 100.00 %\tloss: 0.00005881\n",
      "Validation Acc: 98.52 %\t\tVal loss: 0.00472872\n",
      "Progress: 10.00 %\tAcc: 87.50 %\tloss: 0.01111225\n",
      "Validation Acc: 97.05 %\t\tVal loss: 0.00945878\n",
      "Progress: 20.00 %\tAcc: 100.00 %\tloss: 0.00809026\n",
      "Validation Acc: 97.00 %\t\tVal loss: 0.00947208\n",
      "Progress: 30.00 %\tAcc: 100.00 %\tloss: 0.00009008\n",
      "Validation Acc: 97.52 %\t\tVal loss: 0.00809598\n",
      "Progress: 40.00 %\tAcc: 100.00 %\tloss: 0.00604377\n",
      "Validation Acc: 98.60 %\t\tVal loss: 0.00438314\n",
      "Progress: 50.00 %\tAcc: 100.00 %\tloss: 0.00000898\n",
      "Validation Acc: 97.32 %\t\tVal loss: 0.00820993\n",
      "Progress: 60.00 %\tAcc: 100.00 %\tloss: 0.00001699\n",
      "Validation Acc: 97.95 %\t\tVal loss: 0.00611852\n",
      "Progress: 70.00 %\tAcc: 87.50 %\tloss: 0.010285673\n",
      "Validation Acc: 97.05 %\t\tVal loss: 0.00898306\n",
      "Progress: 80.00 %\tAcc: 100.00 %\tloss: 0.00140855\n",
      "Validation Acc: 97.97 %\t\tVal loss: 0.00613194\n",
      "Progress: 90.00 %\tAcc: 100.00 %\tloss: 0.00001518\n",
      "Validation Acc: 98.83 %\t\tVal loss: 0.00393303\n",
      "Progress: 100.00 %\tAcc: 100.00 %\tloss: 0.00004097\n",
      "Validation Acc: 98.80 %\t\tVal loss: 0.00408961\n",
      "Progress: 0.00 %\tAcc: 100.00 %\tloss: 0.00959658\n",
      "Validation Acc: 98.30 %\t\tVal loss: 0.00508821\n",
      "Progress: 10.00 %\tAcc: 100.00 %\tloss: 0.00012032\n",
      "Validation Acc: 98.20 %\t\tVal loss: 0.00581700\n",
      "Progress: 20.00 %\tAcc: 100.00 %\tloss: 0.00713561\n",
      "Validation Acc: 97.67 %\t\tVal loss: 0.00752067\n",
      "Progress: 30.00 %\tAcc: 100.00 %\tloss: 0.00000601\n",
      "Validation Acc: 98.08 %\t\tVal loss: 0.00602562\n",
      "Progress: 40.00 %\tAcc: 100.00 %\tloss: 0.00001558\n",
      "Validation Acc: 98.72 %\t\tVal loss: 0.00397840\n",
      "Progress: 50.00 %\tAcc: 100.00 %\tloss: 0.00012153\n",
      "Validation Acc: 97.45 %\t\tVal loss: 0.00842500\n",
      "Progress: 60.00 %\tAcc: 100.00 %\tloss: 0.00113229\n",
      "Validation Acc: 98.47 %\t\tVal loss: 0.00477545\n",
      "Progress: 70.00 %\tAcc: 87.50 %\tloss: 0.073026447\n",
      "Validation Acc: 97.45 %\t\tVal loss: 0.00828231\n",
      "Progress: 78.20 %\tAcc: 100.00 %\tloss: 0.00534487"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,10))\n",
    "plt.plot(losses,color='#ff7f0e')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,10))\n",
    "plt.plot(val_losses,color='#ff7f0e')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,10))\n",
    "plt.plot(val_acc,color='#ff7f0e')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,10))\n",
    "plt.plot(train_acc,color='#ff7f0e')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ck=np.random.randint(0,60000-100)\n",
    "inp,y_inp=batch_gen(ck,size=1)\n",
    "logits=model.predict(inp)\n",
    "ans=logits.argmax(axis=1)\n",
    "cor=y_inp.argmax(axis=1)\n",
    "print(\"Prediction:\",ans,\"\\nCorrect:   \",cor)\n",
    "plt.imshow(inp[0].reshape(28,28), cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=4,ncols=4,figsize=[10,10])\n",
    "fig.patch.set_facecolor('white')\n",
    "pme=model.sequence[2].z_out.transpose(3,0,1,2)\n",
    "for i,axi in enumerate(ax.flat):\n",
    "    axi.imshow(pme[i].reshape(pme.shape[-2:]), cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
